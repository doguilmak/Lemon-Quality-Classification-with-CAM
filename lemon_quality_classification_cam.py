# -*- coding: utf-8 -*-
"""Lemon_Quality_Classification_CAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jhURuwLBddmj1iBq2rVF2yU2T-5PlPS1

<h1 align=center><font size = 6>Lemon Quality Classification with Class Activation Map</font></h1>
<br>
<img src="https://cdn.britannica.com/84/188484-050-F27B0049/lemons-tree.jpg" height=450 width=1000 alt="britannica.com">
<small>Picture Source:<a href="https://cdn.britannica.com/84/188484-050-F27B0049/lemons-tree.jpg"> britannica</a>

<br>

<h2>Description</h2>
<p>Lemon dataset has been prepared to investigate the possibilities to tackle the issue of fruit quality control. It contains <i>2.533</i> images <i>(300 x 300 pixels)</i>. Lemon images are taken on a concrete surface. Dataset also includes empty images of this surface.

Dataset contains images of both bad and good quality lemons under slightly different lighting conditions (all under daylight) and sizes.</p>

<br>

<h2>Acknowledgements</h2>
<p>This dataset has been referred from <a href="https://www.kaggle.com/datasets/yusufemir/lemon-quality-dataset">Kaggle</a>.</p>
<br>
<h2>Objective:</h2>
<ul>
  <li>Understand the dataset & cleanup (if required).</li>
  <li>Build classification models to predict the lemon class.</li>
  <li>Also fine-tune the hyperparameters & compare the evaluation metrics of various classification algorithms.</li>
  <li>Build class activation maps (CAM).</li>
</ul>

<br>
<h2>Keywords</h2>
<ul>
  <li>Computer Science</li>
  <li>Classification</li>
  <li>Biology</li>
  <li>Class Activation Map</li>
  <li>Neural Networks</li>
  <li>Lemons</li>
</ul>
<br>

<h2>Objective for this Notebook</h2>

<p>Within the scope of this project, a classification model was builded whether lemons have good quality, bad quality or empty through data obtained from <b>Yusuf Emir Köroğlu</b>.</p>
<div class="alert alert-block alert-info" style="margin-top: 20px">

<li><a href="https://#import">Import Libraries and Packages</a></li>
<li><a href="https://#data_preparation">Dataset Preparation</a></li>
<li><a href="https://#compile_fit">Compile and Fit the Model</a></li>
<li><a href="https://#build_cam">Building Class Activation Maps</a></li>
<li><a href="https://#make_dataframe">Make Dataframe for the Predictions</a></li>
<li><a href="https://#upload_predict">Upload and Predict Your Picture!</a></li>
<br>

<p></p>
Estimated Time Needed: <strong>30 min</strong>
</div>
"""

!unzip -q archive.zip

"""<br>
<h2 align=center id="import">Import Libraries and Packages</h2>
<p>The following are the libraries we are going to use for this lab:</p>
"""

#from tensorflow.keras.applications.resnet50 import preprocess_input
import tensorflow as tf
from tensorflow.keras import layers

from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model, load_model
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
import cv2
import seaborn as sns

import os
import shutil

import datetime

"""<br>
<h2 align=center id="data_preparation">Dataset Preparation</h2>

<p>We are going to separate our dataset.</p>
"""

num_classes = 3
image_resize = 224
batch_size_training = 128
batch_size_validation = 128

data_generator = ImageDataGenerator()

def train_test_split():
    print("SPLITTING STARTED")
    #data_csv = pd.read_csv("DataSet_Final.csv") ##Use if you have classes saved in any .csv file

    root_dir = '/content/'
    classes_dir = ['bad_quality', 'good_quality', 'empty_background']

    #for name in data_csv['names'].unique()[:10]:
    #    classes_dir.append(name)

    processed_dir = '/content/lemon_dataset'

    val_ratio = 0.10
    test_ratio = 0.20

    for cls in classes_dir:
        # Creating partitions of the data after shuffeling
        print("\n Class Name " + cls)
        src = processed_dir +"//" + cls  # Folder to copy images from

        allFileNames = os.listdir(src)
        np.random.shuffle(allFileNames)
        train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),
                                                                  [int(len(allFileNames) * (1 - (val_ratio + test_ratio))),
                                                                   int(len(allFileNames) * (1 - val_ratio)),
                                                                   ])

        train_FileNames = [src + '//' + name for name in train_FileNames.tolist()]
        val_FileNames = [src + '//' + name for name in val_FileNames.tolist()]
        test_FileNames = [src + '//' + name for name in test_FileNames.tolist()]

        print('Total images: '+ str(len(allFileNames)))
        print('Training: '+ str(len(train_FileNames)))
        print('Validation: '+  str(len(val_FileNames)))
        print('Testing: '+ str(len(test_FileNames)))

        # # Creating Train / Val / Test folders (One time use)
        os.makedirs(root_dir + '/train//' + cls)
        os.makedirs(root_dir + '/val//' + cls)
        os.makedirs(root_dir + '/test//' + cls)

        # Copy-pasting images
        for name in train_FileNames:
            shutil.copy(name, root_dir + '/train//' + cls)

        for name in val_FileNames:
            shutil.copy(name, root_dir + '/val//' + cls)

        for name in test_FileNames:
            shutil.copy(name, root_dir + '/test//' + cls)

    print("SPLITTING ENDED")

train_test_split()

TEST_PATH = '/content/test'
TRAIN_PATH = '/content/train'
VALID_PATH = '/content/val'

train_generator = data_generator.flow_from_directory(
  TRAIN_PATH,
  target_size=(image_resize, image_resize),
  batch_size=batch_size_training,
  class_mode='categorical')

validation_generator = data_generator.flow_from_directory(
  VALID_PATH,
  target_size=(image_resize, image_resize),
  batch_size=batch_size_validation,
  class_mode='categorical')

first_batch = train_generator.next()
first_batch

first_batch_images = train_generator.next()[0]
first_batch_images

fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(20, 20)) # define your figure and axes

ind = 0
for ax1 in axs:
    for ax2 in ax1: 
        #image_data = first_batch_images[ind]
        image_data = first_batch_images[ind].astype(np.uint8)
        #ax2.imshow((image_data * 255).astype(np.uint8))
        ax2.imshow(image_data, cmap = "gray")
        ind += 1

fig.suptitle('First Batch of Lemon Images') 
plt.show()

"""<br>
<h2 align=center id="compile_fit">Compile and Fit the Model</h2>
"""

#load_model('/content/model.h5')

def define_model(input_shape, num_classes):
 
  model = Sequential([
    
    layers.Conv2D(16, input_shape=(image_resize, image_resize, 3), kernel_size=(3,3),activation='relu',padding='same'),        
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'),
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),
    layers.GlobalAveragePooling2D(),
    layers.Dense(num_classes, activation='softmax')
  
  ])
  model.summary()
  
  return model

model = define_model(224, 3) # 224x224 as pixels and 3 as lemon classes

model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=tf.keras.optimizers.RMSprop(lr=0.001))
model.fit(train_generator, epochs=32)

model.save("model.h5")
print("Model saved!")

"""<br>
<h2 align=center id="build_cam">Building Class Activation Maps</h2>
"""

gap_weights = model.layers[-1].get_weights()[0]
gap_weights.shape

cam_model  = Model(inputs=model.input, outputs=(model.layers[-3].output,model.layers[-1].output))
cam_model.summary()

class_mapping = train_generator.class_indices
class_mapping

def show_cam(image_value, features, results):
  '''
  Displays the class activation map of an image

  Args:
    image_value (tensor) -- preprocessed input image with size 224 x 224
    features (array) -- features of the image, shape (1, 28, 28, 128)
    results (array) -- output of the sigmoid layer
  '''

  # there is only one image in the batch so we index at `0`
  features_for_img = features[0]
  prediction = results[0]

  # there is only one unit in the output so we get the weights connected to it
  class_activation_weights = gap_weights[:,0]

  # upsample to the image size
  class_activation_features = sp.ndimage.zoom(features_for_img, (224/28, 224/28, 1), order=2)
  
  # compute the intensity of each feature in the CAM
  cam_output  = np.dot(class_activation_features,class_activation_weights)

  # visualize the results
  print(f'Output \nBad quality: {results[0][0]} \nEmpty: {results[0][1]} \nGood quality: {results[0][2]}')
  plt.figure(figsize=(8, 8))
  plt.imshow(cam_output, cmap='jet', alpha=0.5)
  plt.imshow(tf.squeeze(image_value), alpha=0.5)
  plt.show()

def convert_and_classify(image):

  # load the image
  img = cv2.imread(image)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

  # preprocess the image before feeding it to the model
  img = cv2.resize(img, (224, 224)) / 255.0

  # add a batch dimension because the model expects it
  tensor_image = np.expand_dims(img, axis=0)

  # get the features and prediction
  features,results = cam_model.predict(tensor_image)
  
  # generate the CAM
  show_cam(tensor_image, features, results)

convert_and_classify('/content/test/bad_quality/bad_quality_548.jpg')

convert_and_classify('/content/test/empty_background/empty_background_370.jpg')

convert_and_classify('/content/test/good_quality/good_quality_71.jpg')

"""<br>
<h2 align=center id="make_dataframe">Make Dataframe for the Predictions</h2>
"""

test_generator = data_generator.flow_from_directory(
  TEST_PATH,
  target_size=(image_resize, image_resize),
  shuffle=False,
  class_mode='categorical')

filenames=test_generator.filenames

pred=model.predict_generator(test_generator, steps=len(test_generator), verbose=1).round(3)

filenames_df = pd.DataFrame(filenames, columns=['File Path'])
pred_df = pd.DataFrame(pred, columns=['Bad Quality Probability', 'Background Probability','Good Quality Probability'])
model_predictions = pd.concat([filenames_df, pred_df], axis=1)
model_predictions

file_name='model_predictions.csv'
model_predictions.to_csv(file_name, sep=',', encoding='utf-8')

"""<br>
<h2 align=center id="upload_predict">Upload and Predict Your Picture!</h2>
"""

from google.colab import files
from keras.preprocessing import image
from numpy import asarray

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  width = 224
  height = 224
  dim = (width, height)
  path = '/content/' + fn
  img = cv2.imread(path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  img = cv2.resize(img, dim)
  x = asarray(img)
  x = np.expand_dims(x, axis=0)

  image_tensor = np.vstack([x])
  classes = model.predict(image_tensor)
  print("Bad quality: %", round(classes[0][0]*100, 2))
  print("Empty: %", round(classes[0][1]*100, 2))
  print("Good quality: %", round(classes[0][2]*100, 2))

"""<h1>Contact Me</h1>
<p>If you have something to say to me please contact me:</p>

<ul>
  <li>Twitter: <a href="https://twitter.com/Doguilmak">Doguilmak</a></li>
  <li>Mail address: doguilmak@gmail.com</li>
</ul>
"""

from datetime import datetime
print(f"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
